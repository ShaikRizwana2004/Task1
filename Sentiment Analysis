# üì¶ Sentiment Analysis Using Logistic Regression (CODTECH Internship)

# Step 1: Import libraries
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Step 2: Load the dataset (make sure train.csv is in the same folder)
df = pd.read_csv("train.csv")
df = df[['label', 'tweet']]  # Keep necessary columns
df.columns = ['sentiment', 'text']  # Rename for clarity

# Step 3: Text Preprocessing
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    text = re.sub(r'@\w+|\#', '', text)
    text = re.sub(r'[^A-Za-z\s]', '', text)
    text = text.lower()
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return ' '.join(tokens)

df['clean_text'] = df['text'].apply(clean_text)

# Step 4: Visualize Sentiment Distribution
sns.countplot(x='sentiment', data=df)
plt.title("Sentiment Distribution")
plt.xlabel("Sentiment (0 = Negative, 1 = Positive)")
plt.ylabel("Count")
plt.show()

# Step 5: Feature Extraction using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['clean_text']).toarray()
y = df['sentiment']

# Step 6: Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Model Training
model = LogisticRegression()
model.fit(X_train, y_train)

# Step 8: Evaluation
y_pred = model.predict(X_test)
print("üîç Classification Report:\n")
print(classification_report(y_test, y_pred))

# Step 9: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Step 10: Try Sample Predictions
sample = ["I love this product!", "This is the worst thing ever."]
sample_clean = [clean_text(text) for text in sample]
sample_vec = vectorizer.transform(sample_clean)
prediction = model.predict(sample_vec)

for i, text in enumerate(sample):
    print(f"\nText: {text}")
    print(f"Predicted Sentiment: {'Positive' if prediction[i]==1 else 'Negative'}")

# Step 11: Conclusion
print("\n‚úÖ Sentiment Analysis project completed successfully.")
